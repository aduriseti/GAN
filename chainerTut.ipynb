{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chainer as ch\n",
    "# from chainer.backends import cuda\n",
    "# from chainer import Function, gradient_check, report, training, utils, Variable\n",
    "# from chainer import datasets, iterators, optimizers, serializers\n",
    "# from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "# from chainer.training import extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables & Grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = ch.Variable(np.array([5.]))\n",
    "y = x**2 - 2*x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=2*x\n",
    "y = x**2 - z + 1\n",
    "y.backward(retain_grad=True)\n",
    "z.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  2.,  4.],\n",
       "       [ 6.,  8., 10.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ch.Variable(np.array([[1,2,3],[4,5,6]]).astype(np.float32))\n",
    "y = x**2 - 2*x + 1\n",
    "y.grad = np.ones((2,3)).astype(np.float32)\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = L.Linear(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.5211857 , -0.52129376,  0.2944199 ],\n",
       "        [ 0.9014918 , -1.3782756 , -0.08024161]], dtype=float32),\n",
       " array([0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.W.data,f.b.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable([[1., 2., 3.],\n",
       "          [4., 5., 6.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.cleargrads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10. 14. 18.]\n",
      " [10. 14. 18.]] [4. 4.]\n",
      "[[5. 7. 9.]\n",
      " [5. 7. 9.]] [2. 2.]\n"
     ]
    }
   ],
   "source": [
    "f.cleargrads()\n",
    "y.grad = np.ones((2,2)).astype(np.float32)\n",
    "y.backward()\n",
    "y.backward()\n",
    "print(f.W.grad,f.b.grad)\n",
    "f.cleargrads()\n",
    "y.backward()\n",
    "print(f.W.grad,f.b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MulAdd(ch.Function):\n",
    "    def forward(self,inputs):\n",
    "        x,y,z = inputs\n",
    "        return x*y + z\n",
    "    \n",
    "    def backward(self,inputs,grad_next):\n",
    "        x,y,z = inputs\n",
    "        dw, = grad_next\n",
    "        \n",
    "        dx = y*dw\n",
    "        dy = x*dw\n",
    "        dz = dw\n",
    "        return (gx,gy,gz)\n",
    "    \n",
    "#     forward_cpu/backward_cpu\n",
    "#         use if inputs of type np.ndarray\n",
    "    \n",
    "#     foward_gpu/backward_gpu\n",
    "        # similar but inputs of type cupy.ndarray\n",
    "    \n",
    "#     forward/backward\n",
    "#         use if gpu and cpu execution the same\n",
    "\n",
    "# ch.backends.cuda.cupy ~= numpy for many functions, use in gpu forward/backward pass\n",
    "\n",
    "# can abstract w/ xp = ch.backends.cuda.get_array_module()\n",
    "# now np.exp() or cp.exp() is xp.exp() \n",
    "\n",
    "# can define elementwise ops in cuda by ch.backends.cuda.elementwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# diferent train and test tiem behavioer\n",
    "def dropout(x):\n",
    "    if not ch.config.train: # thread specific global\n",
    "        return x\n",
    "    \n",
    "    xp = ch.backends.cuda.get_array_module(x.data)\n",
    "    msk = 2*(xp.random.rand(*x.shape) > 0.5).astype(x.dtype)\n",
    "    return x*mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from chainer import gradient_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# funciton that  extends Link for use in Chain\n",
    "class EltwiseParamProd(ch.Link):\n",
    "    def __init__(self,shape):\n",
    "        super(EltwiseParamProd,self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.W = ch.Parameter(ch.initializers.Normal(scale=1.),shape)\n",
    "    \n",
    "    def __call__(self,x):\n",
    "        return self.W * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gradient_check.numerical_grad checks finite difference gradient approximaition\n",
    "# ch.testing.assert_allclose() same as numpy.testing.assert_allclose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1 = L.Linear(4,3)\n",
    "l2 = L.Linear(3,2)\n",
    "def forward(x): return l2(l1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyProc():\n",
    "    def __init__(self):\n",
    "        self.l1 = L.Linear(4,3)\n",
    "        self.l2 = L.Linear(3,2)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.l2(self.l1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyChain(ch.Chain):\n",
    "    def __init__(self):\n",
    "        super(MyChain,self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.l1 = L.Linear(4,3)\n",
    "            self.l2 = L.Linear(3,2)\n",
    "    \n",
    "    def __call__(self,x):\n",
    "        return self.l2(self.l1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyChain2(ch.ChainList):\n",
    "    def __init__(self):\n",
    "        super(MyChain2,self).__init__(\n",
    "            L.Linear(4,3),\n",
    "            L.Linear(3,2),)\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        return self[1](self[0](x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chainer.optimizers.adam.Adam at 0x118c7e668>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyChain()\n",
    "opt = ch.optimizers.Adam().setup(model)\n",
    "opt.add_hook(ch.optimizer_hooks.GradientClipping(1))\n",
    "opt.add_hook(ch.optimizer_hooks.WeightDecay(0.0005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# directly update\n",
    "x = np.random.uniform(-1, 1, (2, 4)).astype(np.float32)\n",
    "model.cleargrads()\n",
    "loss = F.sum(model(ch.Variable(x)))\n",
    "loss.backward()\n",
    "opt.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# can abstract w/ loss function\n",
    "def lossfun(arg1,arg2):\n",
    "    return F.sum(model(arg1-arg2))\n",
    "\n",
    "y = np.random.uniform(-1, 1, (2, 4)).astype(np.float32)\n",
    "yhat = np.random.uniform(-1, 1, (2, 4)).astype(np.float32)\n",
    "opt.update(lossfun,y,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer\n",
    "Training loop\n",
    "(1) Iterations over training datasets\n",
    "(2) Preprocessing of extracted mini-batches\n",
    "(3) Forward/backward computations of the neural networks\n",
    "(4) Parameter updates\n",
    "(5) Evaluations of the current parameters on validation datasets\n",
    "(6) Logging and printing of the intermediate results\n",
    "\n",
    "dataset abstraction handles (1),(2)\n",
    "\n",
    "trainer abstraction handles (3) - (6)\n",
    "\n",
    "updater handles (3),(4)\n",
    "\n",
    "extension handles (5),(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
